{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from tqdm import tqdm\n",
    "from bson.json_util import loads, dumps\n",
    "import os.path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server version: 4.2.5\n",
      "['ngrams', 'users', 'processed', 'tmp', 'all_tweets', 'processed_new', 'system.views', 'week_04061006', 'week_11061706', 'week_07051305', 'view_week1704', 'week_17042204', 'week_30040605', 'week_23042904', 'week_14052005', 'week_21052705', 'week_28050306']\n"
     ]
    }
   ],
   "source": [
    "# VPN must be active\\n\",\n",
    "\n",
    "database = ''\n",
    "client = MongoClient(\n",
    "    host=[''],\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    "    authSource='')\n",
    "db = client[database]\n",
    "print (\"server version:\", client.server_info()[\"version\"])\n",
    "\n",
    "collections = db.list_collection_names()\n",
    "print(collections)\n",
    "#print(db.command(\"collstats\", \"events\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = 'week_11061706'\n",
    "json_file = 'json_collections/'+collection+'.json'\n",
    "\n",
    "# download the collection locally\n",
    "if not os.path.exists(json_file):\n",
    "    file = open(json_file, \"w\")\n",
    "    n_docs = db[collection].estimated_document_count()\n",
    "    cursor = db[collection].find({})\n",
    "    for document in tqdm(cursor, total=n_docs):\n",
    "        file.write(dumps(document))\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "#create a mongoDB locally\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client[database]\n",
    "if collection not in db.list_collection_names():\n",
    "    collection = db[collection]\n",
    "    file_data = []\n",
    "    count = 0\n",
    "    for line in open(json_file).readlines(): count += 1\n",
    "    for line in tqdm(open(json_file, 'r'),total=count):\n",
    "        file_data.append(loads(line))\n",
    "    collection.insert_many(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server version: 4.2.5\n",
      "['week_11061706']\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "db = client[database]\n",
    "print (\"server version:\", client.server_info()[\"version\"])\n",
    "\n",
    "collections = db.list_collection_names()\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'output/sentiment_profiles/'\n",
    "collection = str(collections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_match_regex(words_list):\n",
    "    words_regex_objs = []\n",
    "    for wd in words_list:\n",
    "        regex_wd = '{}'.format(wd)\n",
    "        words_regex_objs.append(re.compile(regex_wd, re.IGNORECASE))\n",
    "    return(words_regex_objs)\n",
    "\n",
    "def time_to_sec(hhmmss):\n",
    "        [hours, minutes, seconds] = [int(x) for x in hhmmss.split(':')]\n",
    "        x = datetime.timedelta(hours=hours, minutes=minutes, seconds=seconds)\n",
    "        return(x.seconds/86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_profile(word,db,collection):\n",
    "    \n",
    "    pipeline = { 'complete_text': { '$in': words_match_regex(word) } }\n",
    "    \n",
    "    lst = []\n",
    "    for doc in db[collection].find(pipeline):\n",
    "        try:\n",
    "            lst.append([doc['sentiment']['score'],doc['created_at']])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    df = pd.DataFrame.from_records(lst).dropna()\n",
    "    df.columns = ['sentiment','date']\n",
    "    df[['weekday','month','day','time','r1','r2']] = df['date'].str.split(' ',expand=True)\n",
    "    sorter = ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat']\n",
    "    sorterIndex = dict(zip(sorter,range(len(sorter))))\n",
    "    df['weekday_id'] = df['weekday'].map(sorterIndex)\n",
    "\n",
    "    sorter = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    sorterIndex = dict(zip(sorter,range(len(sorter))))\n",
    "    df['month_id'] = df['month'].map(sorterIndex)\n",
    "\n",
    "    df = df.sort_values(by=['month_id', 'day', 'weekday_id', 'time'])\n",
    "\n",
    "    df['date_simple'] = df['weekday']+\" \"+df['month']+\" \"+df['day']\n",
    "\n",
    "    sorter = df['date_simple'].unique()\n",
    "    sorterIndex = dict(zip(sorter,range(len(sorter))))\n",
    "    df['time_id'] = [ time_to_sec(i) for i in df['time'] ]\n",
    "    df['time_axis'] = df['date_simple'].map(sorterIndex)+df['time_id']\n",
    "    df['time_axis'] = df['time_axis'].round(4)\n",
    "\n",
    "    df = df.sort_values(by='time_axis',ascending=True)\n",
    "    df.drop(['weekday','month','day','time','r1','r2','weekday_id','month_id','time_id'], axis=1, inplace=True)\n",
    "\n",
    "    H = 12\n",
    "    c = [(j+1)/H for j in range(24)]\n",
    "    lst = []\n",
    "    for i in df['time_axis']:\n",
    "        a = 'none'\n",
    "        for j in c:\n",
    "            if int(i)+j-(1/H) <= i <= int(i)+j:\n",
    "                a = int(i)+j-(1/H)/2\n",
    "        lst.append(a)\n",
    "    df['time_bin'] = lst\n",
    "    return(df)\n",
    "\n",
    "def save_profile_png(df, word, outdir):\n",
    "    sns.set(rc={'figure.figsize':(15, 5)})\n",
    "    cmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\n",
    "    ax = sns.lineplot(x=\"time_bin\", y=\"sentiment\", data=df, linewidth=0.5, marker='o', linestyle='-', color='firebrick',ci=95)\n",
    "    ax = sns.scatterplot(x=\"time_axis\", y=\"sentiment\", data=df, palette=cmap, alpha=.2, s=10, color='grey')\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_xlim(-0.5,len(df['date_simple'].unique()))\n",
    "    ax.set_ylabel('Sentimient of tweets about COVID-19')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_title(word)\n",
    "    ax.axhline(0, ls='--',color='black')\n",
    "\n",
    "    k = 0\n",
    "    for j in range(len(list(ax.get_xticks())[1:-1])): #set([int(i) for i in list(ax.get_xticks())[1:-1]]):\n",
    "        i = list(ax.get_xticks())[1:-1][j]\n",
    "        lab = df['date_simple'].unique()[int(i)]\n",
    "\n",
    "        tot = df[df['date_simple']==lab].shape[0]\n",
    "        posi = df[(df['date_simple']==lab)&(df['sentiment']>0)].shape[0]\n",
    "        nega = df[(df['date_simple']==lab)&(df['sentiment']<0)].shape[0]\n",
    "        percP = 'Sent. posi: '+\"{:.2f}\".format((posi/tot)*100)+'%'\n",
    "        percN = 'Sent. nega: '+\"{:.2f}\".format((nega/tot)*100)+'%'\n",
    "    \n",
    "        plt.text(i+0.5,min(df['sentiment'])-0.15,lab,horizontalalignment='center')\n",
    "        plt.text(i+0.5,min(df['sentiment'])-0.25,percP,horizontalalignment='center',fontsize=10)\n",
    "        plt.text(i+0.5,min(df['sentiment'])-0.35,percN,horizontalalignment='center',fontsize=10)\n",
    "        plt.axvline(i, 0, 1,color='grey', linestyle='dashed', linewidth=1)\n",
    "        if j == 0:\n",
    "            k = (list(ax.get_xticks())[1:-1][j+1]-i)/2\n",
    "        #plt.axvline(i+k, 0, 1,color='grey', linestyle='dashed', linewidth=1)\n",
    "\n",
    "    plt.savefig(outdir+'-'.join(word)+'.png',bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:23<00:00, 21.54s/it]\n"
     ]
    }
   ],
   "source": [
    "words = [\"año\",\"caso\",\"crisis\",\"gente\",\"gobierno\",\"gracias\",\"madrid\",\"medida\",\"muerto\",\"mundo\",\"país\",\"persona\",\"riesgo\",\"social\",\"vida\"]\n",
    "#words = ['mascarilla','residencia','vacuna','confinamiento','desescalada','trabajo','estado de alarma','UCI','niños','deporte','fase']\n",
    "\n",
    "for word in tqdm(words):\n",
    "    df = create_profile([word],db,collection)\n",
    "    save_profile_png(df,[word],outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweet impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'output/retweet_impact/'\n",
    "collection = str(collections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = {\n",
    "        'retweeted_status': {'$exists': 1}, # it must be a retweet\n",
    "        'in_reply_to_status_id_str': {'$eq': None}, # it must not be a reply\n",
    "        'is_quote_status': False # it must not be a quote\n",
    "        }\n",
    "pipeline = [{'$match': match}]\n",
    "\n",
    "lst = []\n",
    "for doc in db[collection].aggregate(pipeline, allowDiskUse=True):\n",
    "\n",
    "    user_screen_name = doc['user']['screen_name']\n",
    "    retweeted_status_id = doc['retweeted_status']['id']\n",
    "    retweeted_user_screen_name = doc['retweeted_status']['user']['screen_name']\n",
    "\n",
    "    L = [ user_screen_name, \n",
    "         retweeted_status_id,\n",
    "         retweeted_user_screen_name ]\n",
    "\n",
    "    lst.append(L)\n",
    "\n",
    "df = pd.DataFrame.from_records(lst)\n",
    "df.columns = [ 'user_screen_name',\n",
    "              'retweeted_status_id',\n",
    "              'retweeted_user_screen_name' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcirillo/.local/lib/python3.6/site-packages/pandas/core/series.py:679: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "d_retweeted_tweets = df.groupby(['retweeted_user_screen_name'])['retweeted_status_id'].nunique().to_dict()\n",
    "d_retweeting_users = df.groupby(['retweeted_user_screen_name'])['user_screen_name'].nunique().to_dict()\n",
    "\n",
    "df_RI = pd.DataFrame()\n",
    "df_RI['retweeted_user_screen_name'] = df['retweeted_user_screen_name']\n",
    "df_RI['retweeted_tweets'] = df.retweeted_user_screen_name.map( d_retweeted_tweets )\n",
    "df_RI['retweeting_users'] = df.retweeted_user_screen_name.map( d_retweeting_users )\n",
    "df_RI['retweet_impact'] = df_RI['retweeted_tweets'] * np.log(df_RI['retweeting_users'])\n",
    "df_RI = df_RI.sort_values(by=['retweet_impact'],ascending=False).drop_duplicates()\n",
    "df_RI['retweet_impact'] = np.log10(df_RI['retweet_impact'])\n",
    "df_RI = df_RI.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "df_RI.head(10).to_csv(outdir+'top10_retweet_impact.txt',index=None)\n",
    "\n",
    "df_RI.hist('retweet_impact')\n",
    "plt.savefig(outdir+'retweet_impact.png',bbox_inches='tight')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
